{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kkani\\miniconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkani\\AppData\\Local\\Temp\\ipykernel_45528\\1898305291.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['title'] = df['title'].str.replace('[^a-zA-Z ]', '').str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('percent_change_new.csv', header=None, names=['stock', 'title', 'date', 'percent_change'])\n",
    "\n",
    "# Clean headlines (remove special characters, lowercasing)\n",
    "df['title'] = df['title'].str.replace('[^a-zA-Z ]', '').str.lower()\n",
    "\n",
    "# Encode stock symbols\n",
    "label_encoder = LabelEncoder()\n",
    "df['stock'] = label_encoder.fit_transform(df['stock'])\n",
    "\n",
    "# Tokenize and pad headlines\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['title'])\n",
    "sequences = tokenizer.texts_to_sequences(df['title'])\n",
    "headline_data = pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Normalize percentage changes\n",
    "scaler = MinMaxScaler()\n",
    "df['percent_change'] = pd.to_numeric(df['percent_change'], errors='coerce')\n",
    "df['percent_change'].fillna(0, inplace=True)\n",
    "df['percent_change'] = scaler.fit_transform(df[['percent_change']])\n",
    "\n",
    "# Split the dataset\n",
    "X_headline_train, X_headline_test, X_stock_train, X_stock_test, y_train, y_test = train_test_split(\n",
    "    headline_data, df['stock'].values, df['percent_change'].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, headlines, stocks, changes):\n",
    "        self.headlines = headlines\n",
    "        self.stocks = stocks\n",
    "        self.changes = changes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.headlines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'headline': torch.tensor(self.headlines[idx], dtype=torch.long),\n",
    "            'stock': torch.tensor(self.stocks[idx], dtype=torch.float),\n",
    "            'change': torch.tensor(self.changes[idx], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_hidden_dim, output_dim):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_hidden_dim, batch_first=True)\n",
    "        self.fc1 = nn.Linear(lstm_hidden_dim + 1, 128)  # +1 for the stock encoding\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, headlines, stocks):\n",
    "        embedded = self.embedding(headlines)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        combined = torch.cat((lstm_out, stocks.unsqueeze(1)), dim=1)\n",
    "        x = self.relu(self.fc1(combined))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.00031439989106729627\n",
      "Epoch 2, Loss: 0.0004212296335026622\n",
      "Epoch 3, Loss: 0.0003216788754798472\n",
      "Epoch 4, Loss: 0.0031911847181618214\n",
      "Epoch 5, Loss: 0.0004602802509907633\n",
      "Epoch 6, Loss: 0.0008812681771814823\n",
      "Epoch 7, Loss: 0.00015552662080153823\n",
      "Epoch 8, Loss: 0.00122043676674366\n",
      "Epoch 9, Loss: 0.0003198861959390342\n",
      "Epoch 10, Loss: 0.00015673338202759624\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding\n",
    "embedding_dim = 50\n",
    "lstm_hidden_dim = 64\n",
    "output_dim = 1  # For percentage change\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = StockPredictor(vocab_size, embedding_dim, lstm_hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = StockDataset(X_headline_train, X_stock_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # print(batch['headline'].shape, batch['stock'].shape, batch['change'].shape)\n",
    "        outputs = model(batch['headline'], batch['stock'])\n",
    "        loss = criterion(outputs.squeeze(), batch['change'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'stock_prediction_model_new.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockPredictor(\n",
       "  (embedding): Embedding(30521, 50)\n",
       "  (lstm): LSTM(50, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=65, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = StockPredictor(vocab_size, embedding_dim, lstm_hidden_dim, output_dim)\n",
    "\n",
    "# Load the saved state dict\n",
    "model.load_state_dict(torch.load('stock_prediction_model_new.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: TSLA ,  Tesla bankrupt, stock price falls to $0.00\n",
      "Predicted Change in Stock Price: 1.8659482253284212%\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input(stock_name, headline, tokenizer, label_encoder, max_length):\n",
    "    # Clean and tokenize headline\n",
    "    cleaned_headline = headline.lower().replace('[^a-zA-Z ]', '')\n",
    "    # print(cleaned_headline)\n",
    "    tokenized_headline = tokenizer.texts_to_sequences([cleaned_headline])\n",
    "    padded_headline = pad_sequences(tokenized_headline, maxlen=max_length)\n",
    "    # print(padded_headline.shape)\n",
    "\n",
    "    # Encode stock name\n",
    "    encoded_stock = label_encoder.transform([stock_name])\n",
    "    # print(encoded_stock.shape)\n",
    "\n",
    "    return torch.tensor(padded_headline, dtype=torch.long), torch.tensor(encoded_stock, dtype=torch.float)\n",
    "\n",
    "# Example inputs\n",
    "stock_input = \"TSLA\"\n",
    "headline_input = \"Tesla bankrupt, stock price falls to $0.00\"\n",
    "print(\"Input:\", stock_input, \", \", headline_input)\n",
    "\n",
    "# Preprocess inputs\n",
    "headline_tensor, stock_tensor = preprocess_input(stock_input, headline_input, tokenizer, label_encoder, 200)\n",
    "# print(headline_tensor.shape, stock_tensor.shape)\n",
    "\n",
    "# print(stock_tensor.unsqueeze(-1).shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(headline_tensor, stock_tensor).item()\n",
    "\n",
    "# Assuming you used a scaler for the target variable, you need to inverse transform the prediction\n",
    "predicted_change = scaler.inverse_transform([[prediction]])\n",
    "\n",
    "print(f\"Predicted Change in Stock Price: {predicted_change[0][0]}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kkani\\miniconda3\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4662: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "dummy_input = (headline_tensor, stock_tensor)\n",
    "# Export the model\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\", export_params=True, opset_version=10, do_constant_folding=True, input_names=['input'], output_names=['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
